{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial BI & Data Viz Companies - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VISUALIZATION PROJECT Geospatial Business Intelligence (BI)\n",
    "    * Make a geospatial analysis of the `companies` dataset\n",
    "    * Things you know:\n",
    "        - You have a software company with 50 employees\n",
    "        - The company creates video games\n",
    "        - Roles in your company: 20 developers, 20 Designers/Creatives/UX/UI and 10 executives/managers\n",
    "    * Do an analysis about placing the new company offices in the best environment based on the following criteria:\n",
    "        - There should be software engineers working around\n",
    "        - The surroundings must have a good ratio of big companies vs startups\n",
    "        - Ensure you have in your surroundings companies that cover the interests of your team\n",
    "        - Avoid old companies, prefer recently created ones\n",
    "        \n",
    "JSON companies --> MongoDB --> Python:\n",
    "Queries en Jupyter-Notebook --> DataFrame (Pandas) --> columna geopoint con diccionario con type = point y un array con formato array [lat,long]\n",
    "indice geospatial (point) para volver a cargar en MongoDB y hacer nuevas queries (esta vez tocar la parte de queries geo-espaciales $near, etc...) \n",
    "por ej: de todos los puntos, dime el que está más cerca de empresas de videojuegos, o a 1000m\n",
    "para tener el max y min, hay que probarlos todos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymongo to connect Python with MongoDB\n",
    "from pymongo import MongoClient\n",
    "# to work with stats\n",
    "import pandas as pd\n",
    "# to work with dataframes\n",
    "import numpy as np\n",
    "# to work with json\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from flatten_json import flatten\n",
    "# to plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare the data: extract from the companies database the relevant information for the challenge.\n",
    "\n",
    "* company identification\n",
    "    - id (just in case we would need to get more information later)\n",
    "    - name\n",
    "* only currently active company\n",
    "    - 'deadpooled_year' --> not none\n",
    "    \n",
    "* for geolocation analysis & geospatial visualization\n",
    "    - offices.latitude, offices.longitude --> not null\n",
    "    - offices.country_code, offices.city --> not null\n",
    "\n",
    "* to determine if the company is old (negative) o recent (positive)\n",
    "    - founded_year --> not null\n",
    "\n",
    "* to define if it's a small (startup) or a big company:\n",
    "    - number_of_employees --> company size (make sure there are not ficticious and have >= 1 employee)\n",
    "    - investments.funding_round.round_code: 'Angel','seed' --> to associate to startup category\n",
    "    https://support.crunchbase.com/hc/en-us/articles/115010458467-Glossary-of-Funding-Types\n",
    "    - investments.funding_round.funded_year\n",
    "    - ipo.pub_year,ipo.valuation_amount --> to associate with big company   \n",
    "\n",
    "* to match with our team interests: technology & videogames\n",
    "    - category_code: 'software', 'web', 'games_video' --> to filter as 'best match' for our team --> not null\n",
    "    - description: 'software','technology', 'Platform','Social network' --> for a qualitative analysis\n",
    "    - tag_list: 'network', 'online-communities','projects', etc --> for a qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting on default host and port\n",
    "client = MongoClient ('localhost', 27017)\n",
    "\n",
    "# loading the database\n",
    "db = client['companies']\n",
    "\n",
    "# getting the collection\n",
    "companies = db['companies']\n",
    "\n",
    "# defining the main initial query\n",
    "\n",
    "query1 = db.companies.find({'$and':[{'founded_year':{'$ne': None}},\n",
    "                                   {'category_code':{'$ne': None}},\n",
    "                                   {'deadpooled_year':None},\n",
    "                                   {'number_of_employees':{'$gte':1}},\n",
    "                                   {'offices.latitude':{'$ne':  None}},\n",
    "                                   {'offices.longitude': {'$ne':  None}},\n",
    "                                   {'offices.country_code':{'$ne':  None}},\n",
    "                                   {'offices.city':{'$ne':  None}}]},\n",
    "{'_id':1, 'name':1,'founded_year':1,'deadpooled_year':1,'number_of_employees':1,\n",
    " 'category_code':1,'description':1,'tag_list':1\n",
    " 'offices.latitude':1,'offices.longitude':1,'offices.country_code':1,'offices.city':1,\n",
    "'investments.funding_round.round_code':1,'investments.funding_round.funded_year':1,\n",
    " 'ipo.pub_year':1,'ipo.valuation_amount':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st query to get the offices information per company and normalize JSON\n",
    "query1 = db.companies.find({'$and':[{'founded_year':{'$ne': None}},{'category_code':{'$ne': None}},\n",
    "{'deadpooled_year':None},{'number_of_employees':{'$gte':1}},{'offices.latitude':{'$ne':  None}},{'offices.longitude': {'$ne':  None}},\n",
    "{'offices.country_code':{'$ne':  None}},{'offices.city':{'$ne':  None}}]},{'_id':1, 'name':1,'founded_year':1,'deadpooled_year':1, \n",
    "'number_of_employees':1,'offices.latitude':1,'offices.longitude':1,'offices.country_code':1,'offices.city':1,\n",
    "'category_code':1,'description':1,'tag_list':1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices = json_normalize(data=query1, \n",
    "                         record_path='offices', \n",
    "                         meta=['_id','name', 'founded_year','number_of_employees', 'category_code', 'deadpooled_year', 'description', 'tag_list'], \n",
    "                         errors='ignore')\n",
    "\n",
    "offices.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd query to get the startups funding information per company and normalize JSON\n",
    "query2 = db.companies.find({'$and':[{'founded_year':{'$ne': None}},{'category_code':{'$ne': None}},\n",
    "{'deadpooled_year':None},{'number_of_employees':{'$gte':1}},{'offices.latitude':{'$ne':  None}},{'offices.longitude': {'$ne':  None}},\n",
    "{'offices.country_code':{'$ne':  None}},{'offices.city':{'$ne':  None}}]},{'_id':1, 'name':1,'founded_year':1,'deadpooled_year':1, \n",
    "'number_of_employees':1,'investments.funding_round.round_code':1,'investments.funding_round.funded_year':1,\n",
    "'category_code':1,'description':1,'tag_list':1})\n",
    "# pd.DataFrame(query2).iloc[4]['investments']\n",
    "list(query2)[0].keys()\n",
    "# $exists : True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 \n",
    "fundings = json_normalize(pd.concat([pd.DataFrame(i) for i in query2['investments']]).to_dict('investments'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundings = json_normalize(data=query2)\n",
    "fundings.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd query to get the IPO valuation information per company and normalize JSON\n",
    "query3 = db.companies.find({'$and':[{'founded_year':{'$ne': None}},{'category_code':{'$ne': None}},\n",
    "{'deadpooled_year':None},{'number_of_employees':{'$gte':1}},{'offices.latitude':{'$ne':  None}},{'offices.longitude': {'$ne':  None}},\n",
    "{'offices.country_code':{'$ne':  None}},{'offices.city':{'$ne':  None}},{'ipo':{'$ne':  None}}]},{'_id':1, 'name':1,'founded_year':1,'deadpooled_year':1, \n",
    "'number_of_employees':1,'ipo':1,'category_code':1,'description':1,'tag_list':1})\n",
    "\n",
    "valuations = pd.DataFrame(query3)\n",
    "valuations.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load our query to a dataframe to work with                           \n",
    "def cursor_to_df(query):\n",
    "    return pd.DataFrame(list(query))\n",
    "\n",
    "raw_data = cursor_to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking we get all the requested info\n",
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking what kind of variables we have\n",
    "raw_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check all variables we ask without null have 100% data per register + all companies are currently active\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(raw df,norm_df):\n",
    "    locations = json_normalize(bks[\"address\"])\n",
    "    gelocs = locations.apply(lambda e: [e[\"coord\"][0],e[\"coord\"][1]], result_type=\"expand\", axis=1)\n",
    "    clean_df = pd.concat([bks[\"restaurant_id\"],locations[[\"street\",\"zipcode\"]],gelocs], axis=1)\n",
    "    clean_df.rename({1:\"lat\",0:\"long\"}, axis=1, inplace=True)\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_normalize(data= raw_data, record_path='offices', \n",
    "                      meta=['_id', 'category_code', 'deadpooled_year', 'description','founded_year', 'investments', 'ipo', 'name', 'number_of_employees','tag_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Founded year & Nb employees: convert numerical variables into bins as decision parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs_tab = data.describe()\n",
    "cutoffs_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for outliers first:\n",
    "sns.boxplot(x=data['number_of_employees'])\n",
    "# in this case we want a great ratio between big companies and start ups, it's preferible not to remove the big 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['founded_year'])\n",
    "# in this case we want to avoid old companies so it's recommended not to remove them from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_justforplot = data[(data['founded_year']>= data.founded_year.quantile(0.25)) & (data['number_of_employees']<=data.number_of_employees.quantile(0.75))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_justforplot.number_of_employees.hist(bins=20)\n",
    "plt.suptitle('Zoom on 75% companies - nb of employees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we have a look on these variables\n",
    "data_justforplot.founded_year.hist(bins=20)\n",
    "plt.suptitle('Zoom on 75% companies - founded year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to apply bins with Q1,Q2,Q3 and Q4 and be able to automate when refreshing database\n",
    "def bins_q4(df,var):\n",
    "    bins_labels = ['q1','q2','q3','q4']\n",
    "    cutoffs = [cutoffs_tab[var]['min'],cutoffs_tab[var]['25%'],cutoffs_tab[var]['50%'],cutoffs_tab[var]['75%'],cutoffs_tab[var]['max']]\n",
    "    return pd.cut(df[var],cutoffs, labels=bins_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we apply the bins to each var\n",
    "data['founded_year_bins'] = bins_q4(data,'founded_year')\n",
    "# and we check\n",
    "data['founded_year_bins'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for this one\n",
    "data['number_of_employees_bins'] = bins_q4(data,'number_of_employees')\n",
    "data['number_of_employees_bins'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Offices JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data['offices'][raw_data.columns]\n",
    "dict_flattened = (flatten(record, '.') for record in data)\n",
    "data = pd.DataFrame(dict_flattened)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = json_normalize (data=query, record_path=['offices'], meta=['name', 'category_code','number_of_employees','founded_year'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_data(raw_data):\n",
    "    dic_flattened = [flatten(d) for d in raw_data]\n",
    "    data = pd.DataFrame(dic_flattened)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['offices'] = flatten_data(raw_data['offices'])\n",
    "raw_data['offices'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(col):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(row, name=''):\n",
    "        if type(row) is dict:\n",
    "            for x in row:\n",
    "                flatten(row[x], name + x + '_')\n",
    "        elif type(row) is list:\n",
    "            i = 0\n",
    "            for x in row:\n",
    "                flatten(x, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = row\n",
    "\n",
    "    flatten(col)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data['offices'].append(listOfSeries , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flatten_json(sample_object2)\n",
    "json_normalize(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json_normalize (data=raw_data, record_path=['offices'], meta=['name', 'category_code','number_of_employees','founded_year'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def office_per_company(offices):\n",
    "    company_df = pd.DataFrame.from_records(raw_data['offices'])\n",
    "    for company in raw_data['name']:\n",
    "        company_df = raw_data['offices'].apply(pd.DataFrame.from_records)\n",
    "raw_data['offices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_normalize(raw_data, record_path='offices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_normalize(raw_data, record_path='offices', meta=['_id','category_code', 'deadpooled_year', 'description','founded_year', 'investments', 'ipo', 'name', 'number_of_employees', 'tag_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 'Startups': Less than 10 employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the data quantity for our analyse\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.category_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(‘./companies.json’, orient=‘records’, lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
